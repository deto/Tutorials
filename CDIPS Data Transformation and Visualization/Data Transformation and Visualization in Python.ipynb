{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Transformation & Visualization in Python: numpy, pandas, matplotlib, and seaborn\n",
    "## Topics\n",
    "\n",
    "- Array data types with **numpy**\n",
    "- More advanced data manipulations with **pandas**\n",
    "- Python plotting basics with **matplotlib**\n",
    "- **Seaborn** for easy statistical plots\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Today we're covering libraries that are an important part of the core Python data stack - numpy, pandas, matplotlib, and seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Basics\n",
    "Numerical Python is a powerful library of functions, methods, and data types we can used to analyze our data.\n",
    "\n",
    "The main object that numpy provides is the **ndarray**.  They differ in a few fundamental ways from regular Python lists:\n",
    "\n",
    "1. **Arrays cannot be of mixed types.** They can be all integers, floats, strings, logical (or boolean) values, or other immutable values. But they cannot be some characters, some numbers, or any other olio of data types. They also cannot contain mutable types such as lists. So, we can have a list of lists, but not an array of lists. We can, however, have an array of arrays (sortof). Which brings us to:<br><br>\n",
    "2. Arrays can be multidimensional, but they must be rectangular. You can have a list of lists, where the first interior list is 3 elements long, the second 5, and the third 12, but for your multidemsional arrays, every row must have the same number of columns.<br><br>\n",
    "3. We can perform vector operations on them, which can be algebraic functions (like a dot product), or simple replacements of values in a slice of the array.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Arrays\n",
    "Here's one way: start with a list and turn it into an array with the array method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numpy is usually abbreviated as 'np' on import\n",
    "\n",
    "a = [0] * 40\n",
    "print(type(a))\n",
    "a = np.array(a)\n",
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have an array a of 1 row and 40 columns with zeros. But there's a better way to get a vector of zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(40)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also `ones` (but no `twos` or `threes`...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(20)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's how to declare something that's not all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(40)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with range(), you can also give arange() more parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40, 50)  # Start and Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40, 50, 2) # Start, Stop, and increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40,50,.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(5, 6, 100) #from 5 to 6 with 100 items, linear spacing\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.logspace(0, 5, 20) # from 10^0 to 10^5, logarithmic spacing\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said above, you can have arrays with more than one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(  (10, 10)   ) # Note the inner set of parentheses. (Rows, Columns)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or create using python list-of-lists\n",
    "a = [[1, 2, 3, 4, 5], [2, 4, 6, 8, 10], [3, 6, 9, 12, 15]]\n",
    "a = np.array(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To recap: creating numpy arrays:\n",
    "- `np.zeros`: array of 0.0 of specified size\n",
    "- `np.ones` : array of 1.0 of specified size\n",
    "- `np.array`: create numpy array from python list\n",
    "- `np.linspace` : create a numpy array within a given interval with linear spacing\n",
    "\n",
    "You can also load from text using [np.loadtxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html) but pandas is really better for this sort of thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing elements\n",
    "### 1d arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 1d arrays, it's just the same as lists.\n",
    "a = np.arange(10)\n",
    "print('The whole array:',a)\n",
    "print('The fifth element:',a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing conventions work\n",
    "a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, can also index with a list, or with another numpy array\n",
    "a = np.array([2, 4, 6, 8, 10, 12])\n",
    "items = [1, 3, 5, 0] # items we'd like\n",
    "a[items]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = np.array(items) # Also works if 'items' is another numpy array\n",
    "a[items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DOES NOT work with normal python lists\n",
    "# You'd have to write a comprehension or a loop\n",
    "\n",
    "a = [2, 4, 6, 8, 10, 12]\n",
    "items = [1, 3, 5, 0] # items we'd like\n",
    "\n",
    "[a[i] for i in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also index into an array with boolean values\n",
    "- must be the same length as the array (or else get a warning)\n",
    "- doesn't work with regular python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 4, 6, 8, 10, 12])\n",
    "b = np.array([True, True, False, False, False, True])\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very powerful, as we'll see later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d arrays\n",
    "\n",
    "For 2d arrays the indexing is [row, column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3, 4, 5], [2, 4, 6, 8, 10], [3, 6, 9, 12, 15]]\n",
    "a = np.array(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1, 2] # row 1, column 6 (zero-based indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1, :] # entire row 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, 2] # entire column 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing and bools work as they did before, only on each axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy array properties\n",
    "\n",
    "Numpy arrays have two important properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape/size\n",
    "a = np.zeros((5, 10))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a) # just gives you the length of the outer-most dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array type\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every value in a numpy array must be the same type (unlike normal python lists)\n",
    "This is stored in the 'dtype' property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a[0, 0]) # type of a single entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arange makes it 'int64' by default\n",
    "a = np.arange(20)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can tell it to do otherwise\n",
    "a = np.arange(20, dtype='float')\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or can cast from one to the other\n",
    "a = np.arange(20).astype('float')\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1, 3] = 7\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1, 3] *= 2\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the coolest thing I've shown you isn't really that exciting: a range function that can have floats. The real power of arrays is the ability to have one statement affect a large chunk of an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1,:] = 1  # assign '1' to entire row 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,0] = 7 # assign 7 to entire column 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a == 0] = -1 # Assign -1 everywhere array is zero (this works because (a == 0) produces a 2d boolean numpy array)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pause for a moment and think about how we would do this with a for loop in lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of lists of all zeros\n",
    "LoL = [[0]*10 for i in range(10)] #LoL - List of Lists\n",
    " \n",
    "# Set entries in row 1 to 1\n",
    "for i, elem in enumerate(LoL[1]):\n",
    "    LoL[1][i] = 1\n",
    "\n",
    "# Set entries in column zero to 7\n",
    "for L in LoL:\n",
    "    L[0] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take slices of arrays, just as if they were lists:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Math with Arrays\n",
    "We can do math on many values at once with arrays, no for loop required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 100, 2)\n",
    "b = np.arange(50)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b # Pairwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a * b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(a, b) # or can take the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other math functions which apply to every element\n",
    "a = np.linspace(-np.pi, np.pi, 20)\n",
    "np.sin(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also:\n",
    "- `np.exp` : exponential function\n",
    "- `np.log` : logarithm\n",
    "- `np.abs` : absolute value\n",
    "- ... and many others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful numpy functions\n",
    "\n",
    "NumPy is **huge**, with around 1200 pages of [reference documentation](http://docs.scipy.org/doc/numpy/reference/index.html), but all of you will, at some point, use some basic statistics to get a feel for your data. So let's make sure we hit some of those functions:\n",
    "\n",
    "### Random distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.uniform(0, 100, 10) # Low, High, Size of output\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.uniform(0, 100, (3,3)) # Can also give a shape for the third argument\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 1, 10) # Normal distribution with mean=0, std=1, 10 samples\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(5, 3, 1000)  # Draw 1000 numbers from the standard normal distribution with mean 5 and std 3\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a) # Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating on 2d arrays\n",
    "One of the areas where numpy really shines is its ability to quickly operate along an axis of a 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((5,3))# 5 rows, 3 columns\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()  # Sum over all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=0)  # Sum across all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows are axis 0 and Columns are axis 1.  The order here makes sense because its the same order that you use when indexing an array, rows first - then columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=1) # Sum across all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Numpy Arrays for Selection and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(10, dtype=bool)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing and mass-assignment still work\n",
    "a[2:5] = True\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ~ character inverts the boolean array\n",
    "b = ~a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating \"&\" and \"|\"\n",
    "a = np.array([True, False, True])\n",
    "b = np.array([False, False, True])\n",
    "\n",
    "print(\"A and B\")\n",
    "print(a & b)\n",
    "\n",
    "print(\"A or B\")\n",
    "print(a | b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using boolean expressions, you can specifically read out or assign to pieces of the array based on the values in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_less_than_zero = data < 0\n",
    "data_less_than_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data_less_than_zero] = 0   # Replace all values less than zero, with zero\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10)\n",
    "data[data < 0] = 0  # You could also do this without a temporary variable (data_less_than_zero)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(20,5)*10 # Random data from 0 to 10\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me the mean of each row\n",
    "row_means = data.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give me a subset of the data matrix, containing only rows with a mean > 5 and the second column < 4 \n",
    "mean_greater_five = data.mean(axis=1) > 5\n",
    "print(\"mean_greater_five: \", mean_greater_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matrix = data[mean_greater_five, :]\n",
    "new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR, all in one line - without a temporary variable\n",
    "new_matrix = data[ (data.mean(axis=1) > 5), : ]\n",
    "new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Numpy?\n",
    "1. Avoid writing loops (don't re-invent the wheel)\n",
    "2. Most other python data libraries work on top of numpy\n",
    "2. **Efficient Computation**\n",
    "\n",
    "Regarding the second point, numpy is useful because operations using it are many times faster than their pure Python implementations.  This is because numpy processes arrays using code written in 'low-level' languages like C or Fortran.  These languages are much more tedious to write programs in, but run much faster than a 'high-level' language like Python.  However, by using Python to call functions written by other people in low-level languages, you can get the best of both worlds.\n",
    "\n",
    "**Quick performance comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Setup Create a 1000 x 1000 list of lists (2d matrix)\n",
    "N_ROWS = 1000\n",
    "N_COLS = 1000\n",
    "python_matrix = [[1]*N_COLS for i in range(N_ROWS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Add 1 to every entry in the matrix\n",
    "for i in range(N_ROWS):\n",
    "    for j in range(N_COLS):\n",
    "        python_matrix[i][j] += + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# List comprehensions help...a little\n",
    "result = [[x+1 for x in row] for row in python_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit numpy_matrix = np.zeros((1000, 1000))\n",
    "numpy_matrix += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because numpy is able to know that everything is going to be a float, it can do a lot of optimizations to the arrays that it wouldn't be able to do if each element could, conceivably be a different type. Furthermore, a lot of the time is spent checking to make sure i and j aren't too big or small for the size of the lists, while the numpy code just loads the size of the array once and never checks again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Pandas is a great tool for working with data in Python.  The main object in Pandas you will use is the **DataFrame**.  It has several advantages over numpy ndarrays:\n",
    "\n",
    "1. Allows mixed-types\n",
    "2. Label-based row-column indices\n",
    "3. Easy database-like operations (merge, join, groupby, sort, etc...)\n",
    "\n",
    "**If pandas is so great, why'd we just learn about numpy?**\n",
    "- many of the same thigns work on numpy dataframes and pandas arrays\n",
    "- pandas actually uses numpy under the hood\n",
    "- many libraries expect numpy arrays (but easy to cast from pandas to numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # Pandas is usually abbreviated this way in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play around with Pandas, first let's read in some data from file.\n",
    "\n",
    "In the nycflights13 folder, we have a set of files with data on all the flights that departed NYC airports in 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data from a tab-delimited text-file\n",
    "planes = pd.read_table(\"../data/nycflights13/planes.txt\")\n",
    "\n",
    "# Pandas also has read_excel, read_csv, read_json, read_sql and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's this 'plane' variable have in it?\n",
    "print(type(planes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is it?\n",
    "print(planes.shape)  # same as for numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the column labels?\n",
    "print(planes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the row labels?\n",
    "print(planes.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three important types that are used by DataFrames:\n",
    "\n",
    "- DataFrame\n",
    "- Series\n",
    "- Index\n",
    "\n",
    "## Series\n",
    "\n",
    "One-dimensional - represents a single column or row of data.  Only has one Index\n",
    "\n",
    "## DataFrame\n",
    "\n",
    "Two-dimensional.  Has both row and column labels (two Indexes)\n",
    "\n",
    "## Index\n",
    "\n",
    "This represents the row or column labels in Series and DataFrames\n",
    "\n",
    "![DataFrame Vs Series](DataFrameVsSeries_.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(planes.columns)\n",
    "print(type(planes.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Indexing\n",
    "\n",
    "You can grab a single column using\n",
    "```\n",
    "dataframe[column_name]\n",
    "```\n",
    "\n",
    "To grab a row, use:\n",
    "```\n",
    "dataframe.loc[row_name]\n",
    "```\n",
    "\n",
    "And to grab a specific element use:\n",
    "```\n",
    "dataframe.loc[row_name, column_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes.head(10) # show just the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes['manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(planes['manufacturer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you grab a single column, you have a series\n",
    "\n",
    "![ColumnIndex](ColumnIndex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowthree = planes.loc[3]  # We use 3 because the row index is just numbers right now\n",
    "print(rowthree)\n",
    "print(type(rowthree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the row is a 'Series', and it has its own index - the same as the columns of the data frame!\n",
    "\n",
    "![Row Indexing](RowIndex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe index\n",
    "\n",
    "So far the row-index has been numeric (just 0 through ~3300).  However, we might want to use labels here too.\n",
    "\n",
    "To do this, we can select a column to be the dataframe's index\n",
    "\n",
    "**Only do this if the column contains unique data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes.head(5) # Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "planes = planes.set_index('tailnum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes.head(5) # After"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the index column when you read the file in:\n",
    "\n",
    "```python\n",
    "planes = pd.read_table('planes.txt', index_col=0) #Set the first column as the index\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can grab a row by name:\n",
    "planes.loc['N10156']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also use .loc to grab a single value\n",
    "\n",
    "print(planes.loc['N10156', 'model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But now how do I get the 3rd row since we changed the index to tail-numbers?\n",
    "\n",
    "Here's where **iloc** comes into play.\n",
    "\n",
    "Works like **loc** but uses integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(planes.iloc[3]) # Get the third row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(planes.iloc[:, 3]) # Get the third column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Indexing: In-summary\n",
    "\n",
    "You can grab a single column using\n",
    "```python\n",
    "dataframe[column_name]\n",
    "```\n",
    "\n",
    "To grab a row, use:\n",
    "```python\n",
    "dataframe.loc[row_name]\n",
    "```\n",
    "\n",
    "And to grab a specific element use:\n",
    "```python\n",
    "dataframe.loc[row_name, column_name]\n",
    "```\n",
    "\n",
    "If you want to grab rows or column based on their position, use:\n",
    "```python\n",
    "dataframe.iloc[row_number or :, column_number or :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's explore the 'flights' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_table(\"../data/nycflights13/flights.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head(5) # first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.tail(5) # last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sample(5) # random 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform functions along an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average air_time across all flights\n",
    "flights['air_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = flights[['air_time', 'dep_delay', 'arr_delay']]  # Grab only these three columns\n",
    "subset.mean(axis=0)  # Take mean across all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to mean, there's also:\n",
    "- min\n",
    "- max\n",
    "- median\n",
    "- sum\n",
    "- var (for variance)\n",
    "- std (for standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also `sort_values` to sort by one or more columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sort_values(\"air_time\").head(10)\n",
    "\n",
    "# Shortest flights are only ~20 minutes from NYC to Philadelphia or Connecticut!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sort_values(['year', 'month', 'day', 'hour', 'minute']).head(10)\n",
    "\n",
    "# Sorts by year, then by month, then by day....and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**unique()** is useful for checking out the values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['origin'].unique()  # Three departure airports in the NYC area in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying and removing NAs in a dataset\n",
    "How do you find missing values and remove observations for which there are NAs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of some bad rows\n",
    "flights.iloc[835:845, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are there any NAs in the flights dataframe?\n",
    "flights.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting for flights where there is complete data, what are the dimensions?\n",
    "\n",
    "print(\"Original Matrix Shape:\", flights.shape)\n",
    "\n",
    "null_rows = flights.isnull().any(axis=1) # Rows where any value is null\n",
    "complete_rows = ~null_rows  # Invert the boolean series\n",
    "flights_complete = flights.loc[complete_rows]\n",
    "\n",
    "print(\"Complete-rows shape:\", flights_complete.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Why does this work with loc?  \n",
    "\n",
    "Earlier I showed .loc operating on row/column labels.\n",
    "\n",
    "Well, it can also operate on boolean (true/false) lists (or numpy arrays, or **pandas Series**)\n",
    "\n",
    "Above, what is null_rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(null_rows))\n",
    "null_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The great thing about Pandas is that if you pass in a Series, the order of the elements in it doesn't matter anymore.  It uses the index to align the Series to the row/column index of the dataframe.\n",
    "\n",
    "This is very useful when creating a boolean index from one dataframe to be used to select rows in another!\n",
    "\n",
    "Alternately, with removing NA values there is a [dropna](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) function that can be used.\n",
    "\n",
    "Now...back to flights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting specific rows\n",
    "\n",
    "What if we wanted to find the average departure delay for each of the three airports?\n",
    "\n",
    "A few ways we could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewr_delays = []\n",
    "lga_delays = []\n",
    "jfk_delays = []\n",
    "\n",
    "for i in flights.sample(10000).index:  # Only running over a small part, this takes ~2 minutes over the whole thing!\n",
    "    row = flights.loc[i]\n",
    "    origin = row['origin']\n",
    "    delay = row['dep_delay']\n",
    "    \n",
    "    if pd.isnull(delay): continue   #  Skip NaNs\n",
    "        \n",
    "    if origin == 'JFK':\n",
    "        jfk_delays.append(delay)\n",
    "    if origin == 'EWR':\n",
    "        ewr_delays.append(delay)\n",
    "    if origin == 'LGA':\n",
    "        lga_delays.append(delay)\n",
    "        \n",
    "print('JFK Delay: ', sum(jfk_delays) / len(jfk_delays))\n",
    "print('EWR Delay: ', sum(ewr_delays) / len(ewr_delays))\n",
    "print('LGA Delay: ', sum(lga_delays) / len(lga_delays))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A better way\n",
    "\n",
    "lga_rows = (flights['origin'] == 'LGA')\n",
    "print(lga_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk_delays = flights.loc[flights['origin'] == 'JFK', 'dep_delay']\n",
    "ewr_delays = flights.loc[flights['origin'] == 'EWR', 'dep_delay']\n",
    "lga_delays = flights.loc[flights['origin'] == 'LGA', 'dep_delay']\n",
    "\n",
    "print('JFK Delay: ', jfk_delays.mean())  # pandas mean ignores NaNs by default\n",
    "print( 'EWR Delay: ', ewr_delays.mean())\n",
    "print( 'LGA Delay: ', lga_delays.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice and all, but what if there were 100 origins?  \n",
    "\n",
    "Wouldn't want to write 100 lines here!\n",
    "\n",
    "\n",
    "### Using Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one statement\n",
    "flights.groupby('origin')['dep_delay'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's happening here?\n",
    "\n",
    "![GroupByExample](GroupBy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Could group by another variable - with more levels\n",
    "flights.groupby('carrier')['dep_delay'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging tables 'vertically' // Subsetting and re-combining flights from different airlines\n",
    "You will likely need to combine datasets at some point.  For simple acts of stitching two dataframes together, the pandas **concat** method is used.\n",
    "\n",
    "Let's create a data frame with information on flights by United Airlines and American Airlines only, by creating two data frames via subsetting data about each airline one by one and then merging. \n",
    "\n",
    "The main requirement is that the columns must have the same names (may be in different order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting the dataset into two distinct data frames\n",
    "\n",
    "flightsUA = flights.loc[flights.carrier == 'UA',]\n",
    "flightsAA = flights.loc[flights.carrier == 'AA',]\n",
    "\n",
    "print('UA rows:',flightsUA.shape[0])\n",
    "print('AA rows:',flightsAA.shape[0])\n",
    "print('Total rows:',flightsAA.shape[0] + flightsUA.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two data frames\n",
    "\n",
    "flightsUAandAA = pd.concat([flightsUA,flightsAA], axis=0) # axis=1 would stitch them together horizontally\n",
    "print('Combined rows: ',flightsUAandAA.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing special, just be sure the dataframes have the columns with the same names and types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Binding 3 data frames and checking the number of rows')\n",
    "allthree = pd.concat([flightsUA,flightsAA,flightsUAandAA])\n",
    "allthree.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging - by column\n",
    "\n",
    "The `merge` function provides a way to combine two tables together based on the data in them\n",
    "\n",
    "To demonstrate this, we'll look at combining the planes and flights tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that planes has 'tailnum' as an index\n",
    "planes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flights has a column for tailnum - every flight corresponds to a row in planes\n",
    "flights.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to know how many seats (total) were on flights that took off on february first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, subset flights to just have rows for february first\n",
    "\n",
    "feb1_flights = flights.loc[ (flights.month == 2) & (flights.day == 1)]\n",
    "\n",
    "feb1_flights.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to merge the two tables together.  For every row in flights, we're going to add in columns from planes from the row that matches the flights 'tailnum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb1_flights_w_planes = feb1_flights.merge(planes, left_on='tailnum', right_index=True, how='left')\n",
    "feb1_flights_w_planes.head(10) # Let's look at the resulting table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this statement:\n",
    "\n",
    "```python\n",
    "feb1_flights.merge(planes, left_on='tailnum', right_index=True)\n",
    "```\n",
    "\n",
    "'left' refers to the first dataframe (feb1_flights), and 'right' refers to the second dataframe (planes)\n",
    "\n",
    "`left_on='tailnum'` means:  Use the 'tailnum' column for the feb1_flights dataframe\n",
    "\n",
    "We could also supply `right_on` to tell it what column to use in the planes dataframe, but since we want the index, we use `right_index=True` instead (you can't do `right_on='Index'` because what if a column was named Index?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why did we use `how='left'`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(planes.index) - set(feb1_flights.tailnum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2750 planes in the planes table that aren't in the feb1_flights table at all.\n",
    "\n",
    "Here are the different arguments for how and what they'd do:\n",
    "\n",
    "- 'left': use all rows from feb1_flights, and only rows from planes that match\n",
    "    - feb1_flights rows with no corresponding plane row are filled with NaN for the plane columns\n",
    "- 'right': use all rows for planes, and only rows from feb1_flights that match\n",
    "    - plane rows with no corresponding feb1_flights row are filled with NaN for the feb1_flights columns\n",
    "- 'inner': use only rows for airports and flights that match on the dest/faa columns\n",
    "    - if a flight doesn't have an entry in the planes table, it's row is dropped in the result\n",
    "- 'outer': use all rows from both airports and flights\n",
    "    - NaNs filled when they don't correspond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can answer our question now by summing the 'seats' column, which came from the 'planes' table\n",
    "feb1_flights_w_planes['seats'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of seats!  \n",
    "\n",
    "Just for flights leaving three airports in the NYC area on one day.\n",
    "\n",
    "I'm sure all the flights weren't full, but I bet they real number of people departing is at least 80% of that figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Merge example - what are the most common destination airports?\n",
    "The `flights` dataset has destination airports coded, as three-letter airport codes. What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airports = pd.read_table('../data/nycflights13/airports.txt')\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `airports` table gives us a key! Let's merge the `flights` data with the `airports` data, using `dest` in `flights` and `faa` in `airports`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Merging in pandas')\n",
    "flights_readdest = flights_complete.merge(airports, left_on='dest', right_on = 'faa', how='left')\n",
    "flights_readdest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this merged dataset is nice, but do we really need all of this information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_readdest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_sm = flights_readdest[['origin', 'name', 'year', 'month', 'day', 'air_time']]\n",
    "flights_sm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each operation gives us back a dataframe, they are easily chained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtime = flights_complete.merge(airports, left_on='dest', right_on='faa', how='left') \\\n",
    "    .loc[:, ['origin', 'name', 'air_time']] \\\n",
    "    .groupby(['origin', 'name'])['air_time'] \\\n",
    "    .mean()\n",
    "\n",
    "print(airtime.shape)\n",
    "airtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: What's the longest flight from each airport, on average?**\n",
    "\n",
    "Here, 'airtime' is a little abnormal because it's Index has two levels\n",
    "    - First level is the 'origin'\n",
    "    - Second level is the name of the destination\n",
    "    \n",
    "This is because we grouped by two variables.\n",
    "\n",
    "Now we need to group by 'origin' and apply the 'max' function.  Groupby can work for the levels of a multi-index too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtime.groupby(level='origin').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to know where the flight goes?\n",
    "\n",
    "rows = airtime.groupby(level='origin').idxmax() # This returns the indices in airtime where the max was found\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtime[rows] # Index by it to get the max rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could also do it this way\n",
    "\n",
    "airtime.reset_index() # resets the heirarchical index back the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtime.reset_index().groupby('origin')['air_time'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Table // Average flight time from origin to destination\n",
    "\n",
    "Let's put destinations in rows and origins in columns, and have `air_time` as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_airtime = airtime.unstack() # Since airtime has a hierarchical index, we can use unstack\n",
    "pvt_airtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, often you want to pivot just a regular dataframe.  I'll create one from airtime for an example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtime_df = airtime.reset_index()\n",
    "airtime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtime_pv = airtime_df.pivot(index='origin', \n",
    "                columns='name',\n",
    "                values='air_time')\n",
    "airtime_pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-column merge // What's the weather like for departing flights?\n",
    "Flights...get delayed. What's the first step if you want to know if the departing airport's weather is at all responsible for the delay? Luckily, we have a `weather` dataset for that.\n",
    "\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_table('../data/nycflights13/weather.txt')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_complete.columns & weather.columns) # What columns do they share?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flights_weather = flights_complete.merge(weather, \n",
    "                         on=[\"year\", \"month\",\"day\",\"hour\", \"origin\"])\n",
    "\n",
    "print(flights_complete.shape)\n",
    "print(flights_weather.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flights_weather` has less rows.  Default behavior of merge is 'inner' and so this means there are some flight year/month/day/hour/origin combos where we don't have a weather entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's grab flights+weather where the delay was greater than 200 minutes\n",
    "\n",
    "flights_weather_posdelays = flights_weather.loc[flights_weather.dep_delay > 200]\n",
    "flights_weather_posdelays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Anything unusual about these flights?\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(flights_weather.dropna().wind_gust, 30, range=(0, 50), normed=True, label='normal', alpha=.7)\n",
    "plt.hist(flights_weather_posdelays.dropna().wind_gust, 30, range=(0,50), normed=True, label='delayed', alpha=.7)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Wind Gust')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(flights_weather.dropna().pressure, 30,  normed=True, label='normal', alpha=.7)\n",
    "plt.hist(flights_weather_posdelays.dropna().pressure, 30,  normed=True, label='delayed', alpha=.7)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Pressure')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(flights_weather.dropna().hour, 30,  normed=True, label='normal', alpha=.7)\n",
    "plt.hist(flights_weather_posdelays.dropna().hour, 30,  normed=True, label='delayed', alpha=.7)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other tidying\n",
    "## Capitalization issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_complete['dest'].str.lower().head() # For string columns, use .str to access string methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_complete.dest.str.upper().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_complete = flights_complete.drop_duplicates('month', keep='first')\n",
    "flights_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to file\n",
    "\n",
    "Pandas makes writing the results to a file very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to a CSV (comma-seperated value) file\n",
    "\n",
    "# top 20 rows\n",
    "top = flights.head(20)\n",
    "top.to_csv(\"flights_top.csv\")\n",
    "\n",
    "top.to_csv(\"flights_top.csv\", sep=\"\\t\")  # Use tab as a separator instead of comma\n",
    "\n",
    "\n",
    "top.to_excel(\"flights_top.xlsx\", sheet_name='FlightsTop')  # Use tab as a separator instead of comma\n",
    "\n",
    "# You might need to install the openpyxl module for Excel writing to work\n",
    "# To do this, open a terminal and type in \"conda install openpyxl\", then restart the jupyter notebook by\n",
    "# going to Kernel (at the top) and selecting 'Restart'.  You will have to re-run the earlier cells that load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting in Python\n",
    "\n",
    "    - Matplotlib\n",
    "    - Seaborn\n",
    "    - Other Popular Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kind of strange, but this is generally how matplotlib is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First plot\n",
    "plt.figure()\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [1, 6, 9, 6, 1]\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is happening here:\n",
    "\n",
    "- `plt.figure()`: Create a new figure\n",
    "- `plt.plot(...)`: Add a plot to this figure\n",
    "- `plot.show()`: Render the plot\n",
    "\n",
    "In a terminal, `plot.show()` opens a new window.  Code execution halts until you close the window.\n",
    "\n",
    "If you use **ipython** though, you can run `%matplotlib` in order to enable interactive plotting.\n",
    "\n",
    "In jupyter notebook - use `%matplotlib inline` or `%matplotlib notebook`\n",
    "- No need for `plt.show` then.  Any in-progress plots are shown at the end of a cell's execution automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why use `plt.figure`?\n",
    "\n",
    "If you don't create a new figure explicitly, then plots are added to the existing figure.\n",
    "- Unless there is no existing figure.  Then one is just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [1, 6, 9, 6, 1]\n",
    "y2 = [5, 6, 7, 6, 5]\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load some more interesting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "airlines = pd.read_table(\"../data/nycflights13/airlines.txt\")\n",
    "airports = pd.read_table(\"../data/nycflights13/airports.txt\")\n",
    "flights = pd.read_table(\"../data/nycflights13/flights.txt\")\n",
    "planes = pd.read_table(\"../data/nycflights13/planes.txt\")\n",
    "weather = pd.read_table(\"../data/nycflights13/weather.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the weather table - this table contains information on the weather at each of the three origin airports for every hour of 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the total precipitation for each month\n",
    "daily_precip = weather.groupby(['origin', 'month'])['precip'].sum().reset_index()\n",
    "ewr_precip = daily_precip.loc[daily_precip.origin == 'EWR'].sort_values(['month']).precip.values\n",
    "lga_precip = daily_precip.loc[daily_precip.origin == 'LGA'].sort_values(['month']).precip.values\n",
    "jfk_precip = daily_precip.loc[daily_precip.origin == 'JFK'].sort_values(['month']).precip.values\n",
    "\n",
    "print(ewr_precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add multiple line plots to the same axes\n",
    "plt.figure()\n",
    "plt.plot(lga_precip)\n",
    "plt.plot(ewr_precip)\n",
    "plt.plot(jfk_precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's change the style of them\n",
    "plt.figure()\n",
    "plt.plot(lga_precip, 'o', markersize=10)\n",
    "plt.plot(ewr_precip, 'v', markersize=10)\n",
    "plt.plot(jfk_precip, '*', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line/Marker styles in Matplotlib\n",
    "\n",
    "There are 2 ways to set the style for the line and the points on the edges\n",
    "\n",
    "1. Specify each property as its own argument in the plot function\n",
    "\n",
    "    ```python\n",
    "    plt.plot(x, y,\n",
    "            linestyle='solid', linewidth=10, color='blue',\n",
    "            marker='o', markersize=5, markerfacecolor='green', markeredgecolor='red'\n",
    "            )\n",
    "    ```\n",
    "\n",
    "2. Use an abbreviation ([documented here](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot))\n",
    "\n",
    "    ```python\n",
    "    plt.plot(x, y, '-ob')  # Solid line, 'o' marker, blue\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a legend\n",
    "plt.figure()\n",
    "plt.plot(lga_precip, 'o', markersize=10, label='LGA')\n",
    "plt.plot(ewr_precip, 'v', markersize=10, label='EWR')\n",
    "plt.plot(jfk_precip, '*', markersize=10, label='JFK')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a bit more information to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lga_precip, 'o', markersize=10, label='LGA')\n",
    "plt.plot(ewr_precip, 'v', markersize=10, label='EWR')\n",
    "plt.plot(jfk_precip, '*', markersize=10, label='JFK')\n",
    "plt.legend()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Precipitation (inches)')\n",
    "plt.title('Precipitation Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy to save to a variety for formats\n",
    "plt.savefig('precipitation.pdf')\n",
    "plt.savefig('precipitation.svg')\n",
    "plt.savefig('precipitation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots\n",
    "\n",
    "Difference between scatter and plot\n",
    "- Use scatter plots when you want every point to have a different size or color\n",
    "- Let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like this, it's not too different from plt.plot with markersize=5\n",
    "plt.figure()\n",
    "plt.scatter(weather.temp, weather.dewp, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(weather['temp'], weather.dewp, c=weather.humid, s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a x=y line and a colorbar\n",
    "plt.figure()\n",
    "plt.scatter(weather['temp'], weather.dewp, c=weather.humid, s=5)\n",
    "plt.plot([0, 100], [0, 100], '--', color='#aaaaaa', linewidth=.5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we can learn something about temperature, dewpoint, and humidity**\n",
    "\n",
    "- Dewpoint is the temperature which water will condensate on an object\n",
    "- It's linearly dependent on temperature, but there was still not a 1-1 mapping\n",
    "- By adding color, we can see that humidity is the contributor to the difference between temperature and dewpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple plots in a figure - using subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure() # Create a new figure\n",
    "plt.subplot(1, 2, 1) # 1 row, 2 columns, plot #1\n",
    "\n",
    "plt.plot(lga_precip, 'o', markersize=10, label='LGA')\n",
    "plt.plot(ewr_precip, 'v', markersize=10, label='EWR')\n",
    "plt.plot(jfk_precip, '*', markersize=10, label='JFK')\n",
    "plt.legend()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Precipitation (inches)')\n",
    "plt.title('Precipitation Over Time')\n",
    "\n",
    "plt.subplot(1, 2, 2) # 1 row, 2 columns, plot #2\n",
    "\n",
    "plt.scatter(weather.temp, weather.dewp, c=weather.humid, s=5)\n",
    "plt.plot([0, 100], [0, 100], '--', color='#aaaaaa', linewidth=.5)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Temperature (F)')\n",
    "plt.ylabel('Dewpoint (F)')\n",
    "plt.title('Temp vs Dewpoint')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting subplots\n",
    "\n",
    "You'll notice that while we have two plots here, they aren't positioned very nicely.\n",
    "\n",
    "There are three ways to fix this\n",
    "\n",
    "1. Give the plots more space to start with\n",
    "    - When you call `plt.figure`, you can specify a figure size (inches x inches) (demo with 10x5)<br><br>\n",
    "    \n",
    "2.  Manually specify different spacings using `plt.subplots_adjust`\n",
    "    - left = 0.125\n",
    "        - the left side of the subplots of the figure\n",
    "    - right = 0.9\n",
    "        - the right side of the subplots of the figure\n",
    "    - bottom = 0.1\n",
    "        - the bottom of the subplots of the figure\n",
    "    - top = 0.9\n",
    "        - the top of the subplots of the figure\n",
    "    - wspace = 0.2\n",
    "        - the amount of width reserved for blank space between subplots, expressed as a fraction of the average axis width\n",
    "    - hspace = 0.2\n",
    "        - the amount of height reserved for white space between subplots, expressed as a fraction of the average axis height<br><br>\n",
    "3.  Call `plt.tight_layout()` and let matplotlib figure it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close('all') # Close all interactive plots currently open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "Lets look at some histograms in matplotlib\n",
    "\n",
    "To do this, we'll use some of the data in the 'flights' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_departures = (flights.groupby(['origin', 'year', 'month', 'day'])\n",
    "    .size()\n",
    "    .reset_index())\n",
    "\n",
    "ewr_departures = daily_departures.loc[daily_departures.origin == 'EWR'][0]  # .size() put its result in column 0\n",
    "plt.figure()\n",
    "plt.hist(ewr_departures, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multiple histograms - use 'alpha' to overlay\n",
    "\n",
    "jfk_departures = daily_departures.loc[daily_departures.origin == 'JFK'][0]  # .size() put its result in column 0\n",
    "lga_departures = daily_departures.loc[daily_departures.origin == 'LGA'][0]  # .size() put its result in column 0\n",
    "plt.figure()\n",
    "plt.hist(ewr_departures, bins=30, label='EWR', alpha=.6)\n",
    "plt.hist(jfk_departures, bins=30, label='JFK', alpha=.6)\n",
    "plt.hist(lga_departures, bins=30, label='LGA', alpha=.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate plot styles\n",
    "\n",
    "You can use the command 'plt.styles.use' to change the plotting style\n",
    "\n",
    "Matplotlib comes with several options built-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.hist(ewr_departures, bins=30, label='EWR', alpha=.6)\n",
    "plt.hist(jfk_departures, bins=30, label='JFK', alpha=.6)\n",
    "plt.hist(lga_departures, bins=30, label='LGA', alpha=.6)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn\n",
    "\n",
    "Seaborn is a plotting library that is built on top of **matplotlib**\n",
    "\n",
    "You can do anything in seaborn with just matplotlib commands.  Seaborn just makes it much less tedious.\n",
    "\n",
    "Seaborn is useful for:\n",
    "\n",
    "- Heatmaps\n",
    "- Statistical plots\n",
    "- Dealing with Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning seaborn conventions with *jointplot*\n",
    "\n",
    "`jointplot` is a handy function for plotting the joint distribution of two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # This is how seaborn is usually abbreviated\n",
    "plt.style.use('default')\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.jointplot(tips.total_bill, tips.tip)\n",
    "sns.jointplot(tips.total_bill, tips.tip, kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our plot! Some things to notice:\n",
    "\n",
    "- Seaborn has already filled in the x and y labels\n",
    "- This is actually a matplotlib Figure.  The figure has three Axes (subplots)\n",
    "- If we zoom in, the histograms zoom to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=tips.total_bill, y=tips.tip, kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames and Seaborn\n",
    "\n",
    "Seaborn makes it easy to just use dataframes directly.\n",
    "\n",
    "Recall that our 'tips' dataframe has columns 'total_bill' and 'tip'\n",
    "\n",
    "All seaborn plotting functions provide an alternate way of calling them that uses the dataframe directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dataframe columns directly\n",
    "sns.jointplot(x='total_bill', y='tip', data=tips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(vars=['total_bill', 'tip', 'size'], data=tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot - add hue\n",
    "sns.pairplot(vars=['total_bill', 'tip', 'size'], hue='time', data=tips)\n",
    "plt.subplots_adjust(right=.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box/violin\n",
    "\n",
    "These are all plots for showing distributions\n",
    "\n",
    "Let's use a new dataset for this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.boxplot(x='class', y='fare', data=titanic)\n",
    "plt.ylim(0, 200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.boxplot(x='class', y='fare', hue='alive', data=titanic)\n",
    "plt.ylim(0, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.swarmplot(x='class', y='fare', hue='alive', data=titanic)\n",
    "plt.ylim(0, 200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Styles in Seaborn\n",
    "\n",
    "One of seaborns early uses was just to get prettier matplotlib plots.\n",
    "\n",
    "Matplotlib defaults were ugly, but if you just imported seaborn, they'd be set to something that looked nicer.\n",
    "\n",
    "Now, matplotlib (2.0 and up) has decent looking defaults, but seaborn still has some nice options\n",
    "\n",
    "- sns.set_style(*style_name*) can switch between plotting styles\n",
    "    - *style_name* are 'white', 'dark', 'whitegrid', 'darkgrid', 'ticks'<br><br>\n",
    "- sns.despine() removes the top and right axes spines<br><br>\n",
    "- sns.set_context(*context_name*) will scale plot elements\n",
    "    - *context_name* are 'talk', 'paper', 'notebook', 'poster'<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk') # Make text bigger\n",
    "sns.set_style(\"dark\")\n",
    "plt.figure()\n",
    "sns.boxplot(x='class', y='fare', hue='alive', data=titanic)\n",
    "plt.ylim(0, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper') # Make text bigger\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "plt.figure()\n",
    "sns.boxplot(x='class', y='fare', hue='alive', data=titanic)\n",
    "plt.ylim(0, 160)\n",
    "plt.subplots_adjust(left=.2, bottom=.2)\n",
    "sns.despine(offset=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using *FaceGrid* to create plots for every level of a categorical variable\n",
    "\n",
    "Let's visualize the distribution of the number of departures per day, in a separate plot for each month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_per_day = flights.groupby(['origin', 'month', 'day']).size().reset_index()\n",
    "flights_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "g = sns.FacetGrid(data=flights_per_day, col='month', col_wrap=4)\n",
    "g.map(plt.hist, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can add a hue (because why not?)\n",
    "g = sns.FacetGrid(data=flights_per_day, col='month', col_wrap=4, hue='origin')\n",
    "g.map(plt.hist, 0, range=(200, 400), alpha=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's still a little hard to see, let's use box plots instead\n",
    "g = sns.FacetGrid(data=flights_per_day, col='month', col_wrap=4)\n",
    "g.map(sns.boxplot, \"origin\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps\n",
    "\n",
    "Heatmaps are an area where seaborn really makes things a bit easier.\n",
    "\n",
    "You can use 'plt.pcolormesh' to plot a grid of color in matplotlib.  However, you'll have to set up all the tick-labels manually.\n",
    "\n",
    "Here's an example plotting a heatmap with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of departures per hour\n",
    "# Rows - day of the week\n",
    "# Columns - hour of the day\n",
    "# Values - avg # of flights\n",
    "\n",
    "def day_of_week_2013(month, day):\n",
    "    \"\"\"\n",
    "    2013 was NOT a leapyear and started on a Tuesday\n",
    "    \"\"\"\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    day_num = (month-1)*31 + day\n",
    "    if month > 2: day_num -= 3\n",
    "    if month > 4: day_num -= 1\n",
    "    if month > 6: day_num -= 1\n",
    "    if month > 9: day_num -= 1\n",
    "    if month > 11: day_num -= 1\n",
    "    \n",
    "    return days[(day_num) % 7]\n",
    "\n",
    "flights['Weekday'] = [day_of_week_2013(month, day) for month, day in zip(flights.month, flights.day)]\n",
    "\n",
    "counts = flights.groupby(['Weekday', 'hour', 'day', 'month']).size().reset_index()\n",
    "weekday_counts = counts.groupby(['Weekday', 'hour'])[0].mean()\n",
    "weekday_counts = weekday_counts.reset_index()\n",
    "weekday_counts = weekday_counts.pivot(index='Weekday', columns='hour', values=0)\n",
    "weekday_counts = weekday_counts.fillna(0)\n",
    "weekday_counts = weekday_counts.loc[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']] # Sort the weekdays\n",
    "weekday_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(weekday_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's....ok.  But still needs a little work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data2 = weekday_counts.drop([1, 5, 22, 23], axis='columns')\n",
    "sns.heatmap(data2, cmap='YlGnBu', vmin=15, vmax=75)\n",
    "plt.yticks(rotation=20)\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data2 = weekday_counts.drop([1, 5, 22, 23], axis='columns')\n",
    "sns.heatmap(data2, cmap='YlGnBu', vmin=15, vmax=75, annot=True, square=True, cbar=False)\n",
    "plt.yticks(rotation=20)\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustermap - Heatmap+Dendrogram\n",
    "\n",
    "Let's see if we can cluster the days based on how they deviate from the average # of flights in the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea of how every day deviates from the average number of flights in that day of the week\n",
    "counts = flights.groupby(['Weekday', 'hour', 'day', 'month']).size().reset_index()\n",
    "counts['avg'] = [weekday_counts.loc[weekday, hour] for weekday, hour in zip(counts.Weekday, counts.hour)]\n",
    "counts['deviation'] = counts[0] - counts['avg']\n",
    "counts['date'] = [\"{}/{}\".format(month, day) for month, day in zip(counts.month, counts.day)]\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = counts.pivot(index='date', columns='hour', values='deviation').fillna(0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.clustermap(data, col_cluster=False, vmin=-10, vmax=10)\n",
    "plt.sca(cm.ax_heatmap) # More on this in a minute\n",
    "plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Advanced Matplotlib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyplot vs Objects\n",
    "\n",
    "There are two ways to interact with Matplotlib plots\n",
    "\n",
    "When we use `pyplot.plot`  (abbreviated as plt.plot) to plot a picture, we're using the pyplot state machine.\n",
    "\n",
    "This was developed to give a MATLAB-like interface to the plotting system in matplotlib.\n",
    "\n",
    "`plt.plot` creates a plot using the **current axes** in the **current figure**.\n",
    "\n",
    "We could also call methods on these Figures and Axes directly.\n",
    "\n",
    "### Figures and Axes\n",
    "\n",
    "The image below is a single Figure object, with multiple Axes.\n",
    "\n",
    "![Figures/Axes](subplots.png \"Logo Title Text 1\")\n",
    "\n",
    "When we call `plt.plot`, it's acually calling the `plot` method of the current Axes object.\n",
    "\n",
    "\n",
    "*Snippet from the matplotlib.pyplot source on Github*\n",
    "![Pyplot_plot](pyplot_plot.png \"Logo Title Text 1\")\n",
    "\n",
    "Focusing on the red-underlined parts, you can see the function really does two things.\n",
    "\n",
    "1. Get the **current axes** by calling gca()\n",
    "2. Calls ax.plot(...) on that axes and passes the arguments through.\n",
    "\n",
    "*The rest has to do with the 'hold' state which determines if new plots are added to a figure or replace the currentplot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca() # 'gca - Get Current Axes'\n",
    "ax.plot([1, 2, 3, 4, 5], [1, 3, 5, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf() # gcf - 'Get Current Figure'\n",
    "fig.__repr__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Axes and Figure objects provide us with an endpoint to access/modify various aspects of a plot\n",
    "\n",
    "![Anatomy of a Figure](anatomy_of_a_figure.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5)) # Create a new figure\n",
    "ax1 = plt.subplot(1, 2, 1) # Create a subplot (returns an axes)\n",
    "ax2 = plt.subplot(1, 2, 2) # Create the other subplot (returns an axes)\n",
    "\n",
    "sns.boxplot(x='class', y='fare', hue='alive', data=titanic, ax=ax2) # Create our titanic plot, tell seaborn to use axes 2\n",
    "\n",
    "ax1.plot(lga_precip, 'o', markersize=10)\n",
    "ax1.plot(ewr_precip, 'v', markersize=10)\n",
    "ax1.plot(jfk_precip, '*', markersize=10)\n",
    "\n",
    "ax1.set_xlabel(\"Month\") # same as plt.xlabel\n",
    "ax1.set_ylabel(\"Precipitation\") # same as plt.ylabel\n",
    "ax1.set_title(\"Precipitation per month\")\n",
    "\n",
    "ax2.set_title(\"Titanic Survival\")\n",
    "\n",
    "fig.suptitle(\"Some plots!\")\n",
    "\n",
    "fig.subplots_adjust(wspace=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a way to modify the plots that seaborn creates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp = sns.jointplot(x='total_bill', y='tip', data=tips)\n",
    "ax = jp.ax_joint # jointplot has 3 axes.  The main one is in this variable\n",
    "\n",
    "rot = 0\n",
    "for tick in ax.get_yticklabels(): # Rotate the Y tick labels\n",
    "    tick.set_rotation(rot)\n",
    "    rot += 45 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridspec for more complicated figure layouts\n",
    "\n",
    "So far we just showed subplots using multiple axes that evenly divided the plot area.\n",
    "\n",
    "If you wanted to make a more complicated layout (like what Seaborn does in jointplot above) you can use GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "plt.figure()\n",
    "gs = gridspec.GridSpec(2, 2,\n",
    "                       width_ratios=[1,2],\n",
    "                       height_ratios=[4,1]\n",
    "                       )\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1], sharey=ax1)\n",
    "ax3 = plt.subplot(gs[2], sharex=ax1)\n",
    "ax4 = plt.subplot(gs[3], sharex=ax2, sharey=ax3)\n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.plot(lga_precip, 'o', markersize=10)\n",
    "    ax.plot(ewr_precip, 'v', markersize=10)\n",
    "    ax.plot(jfk_precip, '*', markersize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or even crazier layouts\n",
    "\n",
    "plt.figure()\n",
    "gs = gridspec.GridSpec(3, 3)\n",
    "\n",
    "ax1 = plt.subplot(gs[0, :])   # Use row 1, all columns\n",
    "ax2 = plt.subplot(gs[1,:-1])  # Use row 2, all columns but the last one\n",
    "ax3 = plt.subplot(gs[1:, -1]) # Use row 2&3, only the last column\n",
    "ax4 = plt.subplot(gs[-1,0])   # Use the last row, first column\n",
    "ax5 = plt.subplot(gs[-1,-2])  # Use the last row, second column\n",
    "\n",
    "plt.subplots_adjust(wspace=.3, hspace=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other plotting tools\n",
    "\n",
    "- [Plotly](https://plot.ly/python/) (Interactive HTML/JS plots)\n",
    "- [Bokeh](http://bokeh.pydata.org/en/latest/docs/gallery/les_mis.html) (More interactive HTML/JS plots)\n",
    "- [ggpy](https://github.com/yhat/ggpy) (ggplot-style plotting in Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing Remarks\n",
    "\n",
    "Whew, we covered a whole lot here! \n",
    "\n",
    "I wouldn't expect anyone to be an expert in these tools after just one lesson, but hopefully this has given you an idea on the *kinds* of tasks where these tools are used, and how they can help you analyze data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
